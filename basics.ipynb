{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* DO NOT DELETE PRESERVE THIS\n",
    "import torch # Requried to create tensors to store all numerical values\n",
    "import torch.nn as nn # Required for weight and bias tensors\n",
    "import torch.nn.functional as F # Required for the activation functions\n",
    "\n",
    "lss_ints = [0,1,2,3]\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "embedding = nn.Embedding(10, 3)\n",
    "lsstm = nn.LSTM(3,5) # [batch_size, hidden_states]\n",
    "\n",
    "#linear_1 = nn.Linear(5, 10)\n",
    "#linear_2 = nn.Linear(10, 10) # Outputs logits over all notes in the vocabulary\n",
    "\n",
    "linear_1 = nn.Linear(5, 7) # [hidden_states, dense_dim]\n",
    "linear_2 = nn.Linear(7, 4) # [dense_dim, vocab]\n",
    "# Outputs logits over all notes in the vocabulary\n",
    "\n",
    "#input = torch.LongTensor([[1, 2, 3, 4], [4, 3, 1, 2], [4,4,2,2]])\n",
    "input = torch.LongTensor([[0, 2, 3, 1, 1], [1, 3, 1, 2, 1]])\n",
    "y = torch.LongTensor([[0, 3]]).flatten()\n",
    "print(print(f\"input shape: {input.shape}\"))\n",
    "print()\n",
    "\n",
    "emb = embedding(input) # [3, seq_len, embedding_dim]\n",
    "print(f\"Embedding shape: {emb.shape}\")\n",
    "print()\n",
    "\n",
    "outt,(h,c) = lsstm(emb)\n",
    "print(f\"h shape: {h.shape}\")\n",
    "print(f\"outt shape: {outt.shape}\")\n",
    "print()\n",
    "\n",
    "# hh = h.mean(dim = 1)\n",
    "# print(f\"h_mean shape: {hh.shape}\")\n",
    "# print()\n",
    "\n",
    "oo = outt.mean(dim = 2) # [batch_size, seq_len]\n",
    "\n",
    "print(f\"outss_mean shape: {oo.shape}\") #[batch, num_samples, hidden_size]\n",
    "print(oo)\n",
    "print()\n",
    "\n",
    "# x = linear_1(hh)\n",
    "# logits = linear_2(x)\n",
    "\n",
    "x = linear_1(oo)\n",
    "logits = linear_2(x)\n",
    "\n",
    "print(f\"logits shape: {logits.shape}\")\n",
    "print(logits)\n",
    "print()\n",
    "\n",
    "probs = F.softmax(logits, dim=1)\n",
    "\n",
    "print(f\"Probability shape: {probs.shape}\")\n",
    "\n",
    "probs = probs.detach()\n",
    "\n",
    "\n",
    "print(probs.shape)\n",
    "print(y.shape)\n",
    "\n",
    "print(y)\n",
    "\n",
    "# calculate the loss\n",
    "loss = criterion(probs, y)\n",
    "\n",
    "# print the loss\n",
    "print(loss.item())\n",
    "\n",
    "\n",
    "\n",
    "#max_index = np.argmax(probs)\n",
    "# print(f\"Index of probability that is maximum: {torch.argmax(probs).item()}\")\n",
    "\n",
    "# y_pred = lss_ints[torch.argmax(probs).item()] \n",
    "# print(f\"Next predicted class: {y_pred}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
